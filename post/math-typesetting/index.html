<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="https://dzelrahman.github.io/eja_arti/images/favicon.svg">
    
    <link rel="stylesheet" href="https://dzelrahman.github.io/eja_arti/scss/global.min.fb4dd79813ef5075eb6e0a596ca103e09f51efc11a614d013d4d9049d60904b1.css">
    
    <link rel="stylesheet" href="https://dzelrahman.github.io/eja_arti/css/prism.css" />
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    

 






	




<title>Dapatkah Kita Mencegah Kecerdasan Buatan Melampaui Kecerdasan Manusia? | Faris | Personal Blog</title>
<meta name="description" content="Jaan Tallinn menjumpai kata-kata ini pada 2007, dalam sebuah esai online berjudul Staring into The Singularity. Kata ganti “itu” berarti peradaban manusia. Umat manusia akan lenyap, prediksi sang penulis, dengan kemunculan superintelijen atau AI yang mengungguli level kecerdasan manusia di berbagai bidang.
Talinn, seorang programer komputer kelahiran Estonia, memiliki latar belakang di bidang fisika dan punya kecondongan menyelesaikan soal-soal kehidupan laksana satu masalah pemrograman besar. Pada tahun 2013, ia terlibat dalam pendirian Skype, membangun backend untuk aplikasi tersebut.">
<meta property="og:title" content="Dapatkah Kita Mencegah Kecerdasan Buatan Melampaui Kecerdasan Manusia? | Faris | Personal Blog">
<meta property="og:site_name" content="Faris | Personal Blog">
<meta property="og:description" content="Jaan Tallinn menjumpai kata-kata ini pada 2007, dalam sebuah esai online berjudul Staring into The Singularity. Kata ganti “itu” berarti peradaban manusia. Umat manusia akan lenyap, prediksi sang penulis, dengan kemunculan superintelijen atau AI yang mengungguli level kecerdasan manusia di berbagai bidang.
Talinn, seorang programer komputer kelahiran Estonia, memiliki latar belakang di bidang fisika dan punya kecondongan menyelesaikan soal-soal kehidupan laksana satu masalah pemrograman besar. Pada tahun 2013, ia terlibat dalam pendirian Skype, membangun backend untuk aplikasi tersebut.">
<meta property="og:url" content="https://dzelrahman.github.io/eja_arti/post/math-typesetting/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:image" content='https://dzelrahman.github.io/images/superint.jpg'><meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Dapatkah Kita Mencegah Kecerdasan Buatan Melampaui Kecerdasan Manusia? | Faris | Personal Blog">

	<link rel="canonical" href="https://dzelrahman.github.io/eja_arti/post/math-typesetting/">


	<meta name="twitter:description" content="Jaan Tallinn menjumpai kata-kata ini pada 2007, dalam sebuah esai online berjudul Staring into The Singularity. Kata ganti “itu” berarti peradaban manusia. Umat manusia akan lenyap, prediksi sang penulis, dengan kemunculan superintelijen atau AI yang mengungguli level kecerdasan manusia di berbagai bidang.
Talinn, seorang programer komputer kelahiran Estonia, memiliki latar belakang di bidang fisika dan punya kecondongan menyelesaikan soal-soal kehidupan laksana satu masalah pemrograman besar. Pada tahun 2013, ia terlibat dalam pendirian Skype, membangun backend untuk aplikasi tersebut.">
<meta name="twitter:image" content="https://dzelrahman.github.io/images/superint.jpg">
<meta property="article:published_time" content="2019-03-08T00:00:00&#43;00:00">
	<meta property="article:updated_time" content="2019-03-08T00:00:00&#43;00:00">



    </head>


<body class="line-numbers">

    
    <script src="https://dzelrahman.github.io/eja_arti/js/initColors.js"></script>

    <div class="layout-styled">

        <Section class="section">
  <div class="nav-container">
    <a class="logo-link" href="https://dzelrahman.github.io/eja_arti/">
      <!DOCTYPE html><html><head><meta charset='utf-8'><title>Converted document</title></head><body><div><img alt='' src='data:image/png;base64,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'/></div></body>
      <span class="header-hidden">Navigate back to the homepage</span>
    </a>
    <div class="nav-controls">
      <button id="copyButton" class="icon-wrapper">
        <svg
    class="icon-image"
    width="24"
    height="20"
    viewBox="0 0 24 20"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M2 5C2 3.34328 3.34328 2 5 2H14C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13C9 13.5523 9.44771 14 10 14H14C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613 0 14 0H5C2.23872 0 0 2.23872 0 5V9C0 10.4938 0.656313 11.8361 1.6935 12.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625C3.47028 12.2483 3.43068 11.6164 3.0165 11.2511C2.39169 10.6999 2 9.89621 2 9V5ZM7 11C7 9.34328 8.34328 8 10 8H14C14.5523 8 15 7.55228 15 7C15 6.44772 14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11V15C5 17.7613 7.23872 20 10 20H19C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906C21.8923 6.88372 21.2604 6.92332 20.8951 7.3375C20.5297 7.75168 20.5693 8.38361 20.9835 8.74894C21.6083 9.30007 22 10.1038 22 11V15C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11Z"
      fill="#000"
    />
</svg>
        <div id="toolTip" class="tool-tip " >
            copied
        </div>
        <input id="copyText" style="opacity: 0;" type="text" class="tool-tip " />
      </button>

      <button id="themeColorButton" class="icon-wrapper"> 
        <div id="sunRays" class="sun-rays"></div>
        <div id="moonOrSun" class="moon-or-sun"></div>
        <div id="moonMask" class="moon-mask"></div>
      </button>
    </div>
</div>
</Section>


<script src="https://dzelrahman.github.io/eja_arti/js/toggleLogos.js"></script>


<script src="https://dzelrahman.github.io/eja_arti/js/toggleColors.js"></script>


<script src="https://dzelrahman.github.io/eja_arti/js/copyUrl.js"></script>

        

<section class="section narrow">

    <section id="articleHero" class="section narrow">
    <div class="article-hero">
        <header class="article-header">
            <h1 class="article-hero-heading">Dapatkah Kita Mencegah Kecerdasan Buatan Melampaui Kecerdasan Manusia?</h1>
            <div class="article-hero-subtitle">
                <div class="article-meta">
                    


    
            <a href="https://dzelrahman.github.io/eja_arti/authors/faris/" class="article-author-link">
                
                    <div class="article-author-avatar">
                        <img src="https://dzelrahman.github.io/eja_arti/images/new-prof.jpeg" />
                    </div>
                
                
                <strong>Faris</strong>
                
                <span class="hide-on-mobile">,&nbsp;</span>
            </a>
    



<script src="https://dzelrahman.github.io/eja_arti/js/collapseAuthors.js"></script>
                    March 8, 2019
                    • 15 min read
                </div>
            </div>
        </header>
        
        <div class="article-hero-image" id="ArticleImage__Hero">
            <img src="https://dzelrahman.github.io/eja_arti/images/superint.jpg">
        </div>
        
    </div>
</section>


    <aside id="progressBar" class="aside-container">
    <div class="aside-align">
      <div>
        <div class="overlap-container">
        </div>
      </div>
    </div>

    <div class="progress-container" tabIndex={-1}>
        <div class="track-line" aria-hidden="true">
            <div id="progressIndicator" class="progress-line"></div>
        </div>
    </div>
</aside>


    <article  id="articleContent" class="post-content" style="position:relative;">
        <p>Jaan Tallinn menjumpai kata-kata ini pada 2007, dalam sebuah esai online berjudul Staring into The Singularity. Kata ganti “itu” berarti peradaban manusia. Umat manusia akan lenyap, prediksi sang penulis, dengan kemunculan superintelijen atau AI yang mengungguli level kecerdasan manusia di berbagai bidang.</p>

<p>Talinn, seorang programer komputer kelahiran Estonia, memiliki latar belakang di bidang fisika dan punya kecondongan menyelesaikan soal-soal kehidupan laksana satu masalah pemrograman besar. Pada tahun 2013, ia terlibat dalam pendirian Skype, membangun backend untuk aplikasi tersebut. Ia mencairkan sahamnya setelah eBay membelinya dua tahun kemudian, dan saat ini dia sedang mencari kegiatan lainnya untuk dilakukan. Menatap lekat-lekat kode komputer, fisika quantum, dan kutipan-kutipan Calvin dan Hobbes. Dia pun tenggelam di dalamnya.</p>

<p>Tak butuh waktu lama bagi Talinn untuk mengetahui bahwa penulis kata-kata tersebut, Eliezer Yudkowsky, seorang ahli teori otodidak, telah menulis lebih dari 1000 esai dan artikel blog, yang kebanyakannya dicurahkan untuk tema superintelligence (kecerdasan super). Dia membuat suatu program untuk mengumpulkan tulisan-tulisan Yudkowski dari internet, mengurutkannya secara kronologis, dan memformatnya agar dapat dibaca di dalam iphonenya. Kemudian dia habiskan sebagian besar tahun untuk menelitinya.</p>

<p>Istilah kecerdasan buatan, atau simulasi kecerdasan di dalam komputer atau mesin, dicetuskan belakangan di tahun 1965, hanya berselang satu dekade setelah penciptaan komputer digital elektronik pertama. Harapan terhadap bidang ini awalnya tinggi, tetapi pada medio 1970-an, ketika predikisi awal tidak berjalan dengan baik, “musim dingin kecerdasan buatan” tiba. Ketika Talinn menemukan esai Yudkowsky, AI sedang mengalami masa kebangkitan. Para Ilmuwan sedang mengembangkan kecerdasan buatan yang unggul dalam bidang-bidang tertentu, seperti memenangi permainan catur, membersihkan lantai dapur, dan mengenali perkataan/ucapan manusia. “Kecerdasan buatan yang dangkal” itu, seperti mereka sebut, mempunyai kemampuan manusia super, tetapi hanya dalam bidang-bidang yang mereka dominan. Kecerdasan buatan yang pandai bermain catur takkan mampu membersihkan lantai atau mengantar anda dari titik A ke titik B. Kecerdasan buatan dengan kecerdasan super, Talinn meyakini, akan menyatukan berbagai kecakapan dalam satu entitas. Lebih ngeri lagi, kecerdasan buatan juga mungkin menggunakan pula data yang dikumpulkan dari para pengguna ponsel pintar untuk unggul dalam manipulasi sosial.</p>

<p>Membaca artikel Yudkowsky, Talinn menjadi yakin bahwa kecerdasan super dapat mengarah pada letupan kecerdasan buatan yang dapat mengancam eksistensi manusia-bahwa kecerdasan buatan ultra cerdas akan mengambil alih posisi manusia di tangga evolusi dan menguasai diri kita sebagaimana kita saat ini menguasai kera. Atau yang lebih buruk lagi, membinasakan diri kita.</p>

<p>Setelah menyudahi akhir esai Yudkowsky, Talinn mengirimkan sebuah email kepadanya — dengan huruf kecil, seperti gayanya. “nama saya jaan, salah satu pendiri skype,” tulisnya. Alhasil sampailah ia pada kalimat: “saya setuju bahwa…menyiapkan munculnya kecerdasan buatan umum yang akan melampaui kecerdasan manusia adalah salah satu tugas utama bagi umat manusia.” Membaca email ini, Yudkowsky lantas langsung bersedia membantu.</p>

<p>Saat Talinn terbang ke Bay Area untuk menghadiri pertemuan lanjutan seminggu kemudian, ia bertemu dengan Yudkowsky, yang tinggal berdekatan dengan lokasi pertemuannya, di sebuah kafe di Millbrae, California. Diskusi mereka berlangsung hingga empat jam. “Dia benar-benar memahami konsep dan detail dasarnya; kata Yudkowsky yang menceritakannya padaku baru-baru ini. “Ini sangatlah langka.” Setelahnya, Talinn menulis cek dengan nominal sebesar $5000 untuk Singularity Institute for Artificial Intelligence, organisasi nirlaba dimana Yudkowsky bekerja sebagai peneliti. (Organisasi itu berganti nama menjadi Machine Intelligence Research Institute, atau MIRI, di tahun 2013.) Sejak saat itu, Talinn telah menyumbangkan dana lebih dari $600,000 kepada lembaga itu.</p>

<p>Pertemuan dengan Yudkowsky memberi tujuan bagi Talinn, mengirim dirinya menuju sebuah misi untuk menyelamatkan kita dari ciptaan kita sendiri. Dia mulai merintis perjalanan hidup yang penuh dengan perjalanan dan menyajikan ceramah tentang ancaman yang ditimbulkan oleh kecerdasan super ke seluruh dunia. Namun, kebanyakan, ia lebih banyak mendanai penelitian tentang metode yang mungkin menyediakan jalan keluar bagi umat manusia: apa yang disebut sebagai kecerdasan buatan ramah. Hal ini bukan berarti bahwa suatu mesin sangat luwes ketika berbicara mengenai cuaca, atau mesin itu mampu mengingat nama anak-anak anda- meskipun kecerdasan buatan yang sangat cerdas mungkin dapat melakukan keduanya. Kemampuan ini bukan berarti digerakkan oleh altruisme dan cinta. Kekeliruan yang umum terjadi adalah berasumsi bahwa kecerdasan buatan mempunyai dorongan dan nilai yang dimiliki manusia. “Ramah” berarti menunjukan sesuatu hal yang jauh lebih mendasar: bahwa mesin masa depan tidak akan memusnahkan kita dalam upaya untuk mencapai tujuannya.</p>

<p>Pada musim semi lalu, saya bergabung menyertai Talinn dalam acara makan malam di ruang makan Jesus College, Universitas Cambridge. Ruangan seperti gereja itu dihiasi dengan jendela-jendela kaca patri, cetakan emas, dan lukisan-lukisan minyak bergambar lelaki dengan rambut palsu. Talinn duduk di meja mahoni tebal, mengenakan pakaian santai khas sillicon valley: celana jins hitam, kaos oblong, dan sepatu kanvas. Langit-langit kayu berkubah terpancang tinggi di atas rambutnya yang berwarna abu-abu terang.</p>

<p>Di usia 47 tahun, Talinn adalah entrepeneur teknologi yang patuh pada teks. Dia menduga bahwa berkat kemajuan dalam sains (dengan asumsi kecerdasan buatan tidak menghancurkan kita), dirinya akan hidup selama “bertahun-tahun.” Ketika pergi clubbing dengan para peneliti, dia bahkan sanggup bertahan lebih lama dari mahasiswa pasca sarjana yang lebih muda. Keprihatinan Talinn terhadap kecerdasan super lazim di antara orang-orang dekatnya. Yayasan milik salah satu pendiri paypal Peter Thiel telah mendonasikan $1.6 juta kepada MIRI, dan pada 2015, pendiri Tesla Elon Musk menyumbangkan $10 juta kepada Future of Life Institute, sebuah organisasi keamanan teknologi di Cambridge, Massachussets. Tapi pintu masuk Talinn ke bidang yang keropos ini datang dari balik tirai besi (iron curtain)-yang memisahkan antara blok soviet dan negara-negara barat- pada tahun 1980-an, ketika ayah teman sekelasnya yang bekerja di pemerintahan memberi beberapa anak-anak cerdas akses menuju komputer utama. Selepas Estonia merdeka, Talinn mendirikan perusahaan video-game. Saat ini Talinn masih bertempat tinggal di ibu kota Estonia-yang juga bernama Talinn-bersama istrinya dan anaknya yang paling kecil dari keenam anaknya. Ketika dia ingin bertemu dengan para peneliti, seringkali dia tinggal menerbangkan mereka ke wilayahnya di Baltik ini.</p>

<p>Strategi pemberian dana Talinn sangat metodis, seperti nyaris semua hal yang dia kerjakan. Dia menyebarkan dananya ke 11 organisasi, masing-masing bergerak dengan pendekatan yang berbeda mengenai keamanan kecerdasan buatan, dengan harapan salah satunya akan bertahan. Di tahun 2012, ia mendirikan Centre for The Study of Existential Risk (CSER) dengan pengeluaran awal mendekati $200.000.</p>

<p>Risiko eksistensial-atau risiko X, seperti yang disebut Talinn- merupakan ancaman terhadap kelangsungan hidup umat manusia. Selain kecerdasan buatan, 20 peneliti tak tetap di CSER juga mempelajari perubahan iklim, perang nuklir, dan senjata biologi. Tetapi bagi Talinn, bidang disiplin lain itu hanyalah pemicu saja. Perhatian mengenai ancaman yang diterima lebih luas oleh publik, seperti perubahan iklim, barangkali akan menarik masyarakat untuk ikut berpartisipasi. Ketakutan akan mesin kecerdasan super yang mengambil alih dunia, dia harapkan, akan meyakinkan orang untuk bertahan. Dia menyambangi Cambridge untuk sebuah konferensi lantaran dia ingin komunitas akademik menganggap isu keamanan kecerdasan buatan secara lebih serius.</p>

<p>DI Jesus College, rekan makan kami terdiri dari beragam pengunjung konferensi, temasuk seorang wanita Hongkong yang mempelajari robotika dan seorang pria inggris yang lulus dari Cambridge pada era 1960-an. Pria yang lebih tua menanyakan kepada setiap orang yang duduk di meja, dimana tempat mereka dulu berkuliah. (Jawaban Talinn, Universitas Tartu Estonia, tidak membuat pria tua itu terkesan). Ia kemudian coba mengalihkan percakapan menjadi (tentang) berita-berita yang tersebar. Talinn menatap pria tua itu dengan tatapan kosong. “Saya tidak berminat pada risiko jangka pendek,” katanya.</p>

<p>Talinn mengalihkan topik percakapan menjadi tentang ancaman kecerdasan super. Ketika tidak sedang berbicara dengan rekan sesama programmer, dia menyampaikan gagasannya dengan bahasa-bahasa metafora, seperti: kecerdasan buatan dapat memusnahkan kita secepat manusia menebang pepohonan. Kecerdasan buatan bagi kita layaknyai manusia bagi gorila.</p>

<p>Kecerdasan buatan akan memerlukan sebuah jasad untuk mengambil alih peran manusia, kata pria tua itu. Tanpa semacam bingkai fisik, bagaimana mungkin mereka sanggup berkuasa atas fisik?</p>

<p>Talinn telah siap dengan metafora lainnya: “Tempatkan saya di ruangan bawah tanah dengan sebuah koneksi internet, dan saya sanggup membuat banyak kerusakan,” katanya sambil menggigit sepotong risoto.</p>

<p>Setiap kecerdasan buatan, baik itu Roomba atau salah satu penerusnya yang mendominasi dunia, dipicu oleh satu tujuan yaitu hasil. Ahli pemrograman menetapkan sasaran-sasaran ini bersama dengan serangkaian aturan mengenai cara mencapainya. Kecerdasan buatan tingkat lanjut tidak mesti diberi tujuan seperti menguasai dunia untuk mencapainya-bisa saja tujuan ini tercapai secara kebetulan. Dan sejarah pemrograman komputer dipenuhi dengan kesalahan-kesalahan kecil yang berujung bencana. Di tahun 2010, misalnya, ketika seorang trader perusahaan reksa dana Waddell &amp; Reed menjual ribuan kontrak berjangka, perangkat lunak yang dibangun perusahaan luput menyertakan variabel kunci algoritma yang dapat membantu menyelenggarakan perdagangan. Hasilnya adalah kejadian “flash crash” sebesar triliunan dolar AS.</p>

<p>Para peneliti yang dibiayai Talinn meyakini bahwa jika struktur ganjaran dari superhuman AI tidak dirancang dengan baik, bahkan tujuan yang tak berbahaya dapat menjadi berbahaya. Salah satu contoh termasyhur, seperti dikemukakan oleh filsuf Universitas Oxford Nick Bosrom yang tertera di dalam bukunya Superintelligence, adalah sebuah agen fiksi yang diarahkan untuk menciptakan sebanyak mungkin penjepit kertas. Kecerdasan buatan barangkali akan berpendapat bahwa atom-atom dalam tubuh manusia lebih baik digunakan sebagai bahan baku.</p>

<p>Pandangan Talinn ini memiliki pengkiritiknya sendiri, bahkan di antara komunitas yang peduli dengan keamanan kecerdasan buatan. Beberapa pengkritik menyanggah dengan mengatakan bahwa terlalu dini untuk membatasi kecerdasan super ketika kita belum sepenuhnya paham mengenai kecerdasan buatan. Yang lain mengatakan bahwa terlalu fokus pada aktor teknologi jahat dapat mengalihkan perhatian dari masalah paling urgen yang dihadapi bidang ini, seperti kenyataan bahwa sebagian besar rumus algoritma ditulis oleh mereka yang berkulit putih, atau didasarkan pada data yang bias (menguntungkan mereka kulit putih). “Akan menjadi sangat berbahaya ketika kita membangun dunia yang enggan kita tinggali jika kita tidak memecahkan tantangan tersebut dalam waktu dekat,” kata Terah Lyons, direktur eksekutif Partnership for AI, sebuah konsorsium industri teknologi yang fokus pada isu-isu mengenai keamanan kecerdasan buatan dan isu-isu lain. (Beberapa institut yang didanai Tallinn merupakan anggota konsorsium ini.) Namun, ia menambahkan, beberapa tantangan jangka pendek yang dihadapi para peneliti, seperti mengeliminasi bias algoritmik, merupakan suatu pendahuluan kecerdasan super yang mungkin dapat dilihat umat manusia.</p>

<p>Tallinn tidak sepenuhnya yakin. Dia membantah dengan berkata bahwa kecerdasan super membawa ancaman yang unik dan berbeda. Pada akhirnya, ia berharap komunitas AI dapat mengekor jejak gerakan anti nuklir di tahun 1940-an. Setelah tragedi pemboman yang menghunjam Hiroshima dan Nagasaki, para ilmuwan bersatu padu untuk coba membatasi pengujian nuklir lanjutan. “Para ilmuwan Proyek Manhattan bisa saja mengatakan: ‘Lihat, kami melakukan inovasi pada proyek ini, dan inovasi pastilah selalu baik, jadi mari kita teruskan proyek ini pengujian ini,’” katanya kepada saya. “Tapi mereka lebih punya rasa tanggung jawab.”</p>

<p>Talinn mengingatkan bahwa segala pendekatan demi terwujudnya keamanan kecerdasan buatan akan sulit dilakukan dengan tepat. Jika kecerdasan buatan cukup pintar, ia bisa jadi mempunyai pemahaman yang lebih baik mengenai kendala-kendala yang mungkin terjadi daripada penciptanya. Bayangkan, katanya, “terbangun di suatu penjara yang dibangun oleh sekumpulan bocah buta berumur lima tahun.” Mungkin seperti itulah yang dirasakan oleh kecerdasan super yang dibatasi pergerakannya oleh manusia.</p>

<p>Ahli teori Yudkowsky menemukan bukti tentang kemungkinan benarnya pemahaman ini ketika, mulai tahun 2002, ia mengadakan sesi obrolan di mana ia memainkan peran AI yang terkurung dalam sebuah peti, sementara orang lain melalui rotasi memainkan peran sebagai penjaga gerbang yang bertugas menjaga AI agar tetap berada di dalam peti. Tiga dari lima kali percobaan, Yudkowsky — seorang manusia belaka — mengatakan bahwa dia berhasil meyakinkan penjaga gerbang untuk melepaskannya dari peti. Meski begitu, eksperimen Yudkowsky ini tidak membuat para peneliti patah arang untuk merancang peti yang lebih baik.</p>

<p>Para peneliti yang didanai Tallinn sedang memikirkan sejumlah strategi, dari yang praktis hingga yang tampak dibuat-buat. Beberapa peneliti mengajukan teori agar Ai dikurung dalam sebuah kotak, baik kotak secara fisik, yaitu dengan membangun struktur aktual untuk mengekang AI tersebut, atau dengan memprogram batas-batas apa saja yang dapat kecerdasan buatan lakukan. Peneliti lain mencoba untuk mengajarkan kecerdasan buatan agar mematuhi norma-norma manusia. Beberapa peneliti lain mencari cara untuk menonaktifkan kecerdasan buatan sebagai usaha terakhir. Salah satu peneliti yang mendalami ketiganya adalah ahli matematika dan filsuf Stuart Armstrong di Future of Humanity Institute, Universitas Oxford, yang Tallinn sebut sebagai “tempat paling menarik di alam semesta.” (Tallinn telah memyumbang lebih dari $ 310.000 kepada FHI.)</p>

<p>Armstrong merupakan satu dari sedikit peneliti di dunia yang memfokuskan seluruh waktunya pada isu keamanan kecerdasan buatan. Saat saya menemuinya untuk minum kopi di Oxford, dia mengenakan kemeja rugby dengan kancing terbuka dan tampak seperti orang yang menghabiskan hari-harinya di belakang layar komputer, dengan wajah pucat yang dibingkai oleh rambut pirang berantakan. Dia membumbui penjelasannya dengan campuran referensi budaya populer dan matematika yang membingungkan. Ketika saya bertanya kepadanya, bagaimana rasanya berhasil dalam bidang keamanan AI, ia berkata, “Apakah Anda pernah menonton film Lego? Semua berasa luar biasa.”</p>

<p>Salah satu jenis penelitian Armstrong adalah melakukan pengamatan pada konsep pengurungan dalam peti yang dinamakan “oracle” AI. Dalam sebuah makalah di tahun 2012 yang ditulis bersama Nick Bostrom, peneliti yang ikut mendirikan FHI, ia mengusulkan agar tidak hanya membatasi kecerdasan super pada sebuah tangki pengurungan — struktur fisik — tetapi juga membatasinya agar hanya dapat menjawab pertanyaan, seperti versi cerdas dari papan Ouija. Bahkan dengan batasan-batasan ini pun, AI tetap akan memiliki banyak kekuatan untuk menentukan (kembali) nasib manusia dengan secara halus mengakali penanyanya. Untuk mengurangi peluang terjadinya kemungkinan ini, Armstrong mengusulkan diaturnya batas waktu dalam percakapan, atau melarang pertanyaan yang mungkin dapat merubah tatanan dunia saat ini. Dia juga memberi saran agar memberikan oracle ukuran proxy kelangsungan hidup manusia, layaknya Dow Jones industrial average atau jumlah orang yang menyeberang jalan di Tokyo, dan meminta untuk menjaga ukuran itu agar tetap stabil.</p>

<p>Pada akhirnya, Armstrong meyakini, mungkin diperlukan untuk menciptakan, seperti yang disebutnya dalam satu jurnal, “tombol merah besar”: baik itu saklar fisik, atau mekanisme yang dibubuhi ke dalam kecerdasan buatan agar secara otomatis mematikan dirinya sendiri jika terjadi kejadian tertentu. Namun merancang sakelar seperti itu jauh dari kata mudah. Alasannya bukan saja kecerdasan buatan canggih yang perhatian pada pemeliharaan diri dapat mencegah tombol itu untuk ditekan. Kecerdasan buatan tersebut juga bisa menjadi penasaran perihal mengapa manusia merancang sebuah tombol, memencet tombol tersebut untuk memeriksa apa yang bakal terjadi, dan mematikan fungsi tombol tersebut. Pada 2013, seorang programmer bernama Tom Murphy VII merancang AI yang dapat mengajarkan dirinya sendiri untuk bermain game Nintendo Entertainment System. Memastikan untuk tidak kalah di permainan Tetris, kecerdasan buatan hanya (tinggal) menekan tombol pause — dan membuat gamenya berhenti. “Sungguh, satu-satunya langkah untuk mencapai kemenangan bukanlah dengan ikut bermain,” Murphy mengamati dengan pahit dalam artikelnya yang membahas tentang kecerdasan buatan ciptaannya.</p>

<p>Agar strategi ini berhasil, kecerdasan buatan harus dibuat untuk tidak tertarik pada tombol, atau, seperti yang Tallinn katakan: “kecerdasan buatan harus menetapkan nilai yang seimbang antara sebuah dunia tanpa tanpanya dan dunia dengan dengannya.” Tetapi meskipun para peneliti dapat mencapai hal tersebut, ada tantangan lainnya. Bagaimana jika kecerdasan buatan telah menyalin dirinya sendiri sebanyak ribuan kali di internet?</p>

<p>Pendekatan yang paling membangkitkan gairah para peneliti adalah (dengan) menemukan cara untuk menjadikan kecerdasan buatan menaati nilai-nilai manusia — bukan dengan memprogram nilai-nilai itu, tetapi dengan mengajarkan kecerdasan buatan untuk mempelajarinya. Di dunia dominan oleh politik partisan, orang sering memikirkan cara-cara agar terjadi perbedaan atas prinsip-prinsip yang kita anut. Tetapi, Tallinn mengatakan pada saya bahwa manusia punya banyak kemiripan: “Nyaris setiap orang menghargai kaki kanan mereka. Hanya saja kita tidak pernah memikirkannya.” Harapannya adalah bahwa AI dapat diajari untuk meninjau aturan yang sudah baku.</p>

<p>Dalam prosesnya, kecerdasan buatan perlu untuk mempelajari dan menghargai sisi manusia yang kurang logis: yaitu seringnya kita mengatakan satu hal padahal maksudnya berbeda, bahwa sebagian preferensi yang kita miliki tak selaras dengan preferensi kita yang lain, dan bahwa orang kurang dapat dipercaya ketika sedang mabuk. Terlepas dari tantangan tersebut, Tallinn percaya, cara-cara itu patut dicoba karena perjudiannya sangat besar. “Kita harus mulai memikirkan sejumlah langkah ke depan,” katanya. “Membuat kecerdasan buatan yang tidak sesuai dengan tujuan kita akan menjadi satu kesalahan yang buruk.”</p>

<p>Pada malam terakhirnya di Cambridge, saya menyertai Tallinn dan dua peneliti lain untuk makan malam di restoran steak. Seorang pelayan menyiapkan kami tempat duduk di ruang bawah tanah putih dengan suasana seperti gua. Dia memberi kami satu halaman menu yang menyajikan tiga jenis mash. Sepasang suami istri duduk di meja sebelah kami, dan kemudian sesaat setelahnya minta pindah ke tempat lain. “Tempat ini terlalu sesak,” keluh wanita itu. Saya teringat komentar Tallinn tentang kerusakan yang bisa dia lakukan jika dikurung di ruang bawah tanah dengan tanpa bekal apapun kecuali koneksi internet. Inilah kami, berada di dalam “peti” itu. Seolah diberi isyarat, siapapun akan memikirkan cara untuk keluar dari tempat tersebut</p>

<p>Para tamu undangan Tallinn salah satunya adalah mantan peneliti genomik Seán Ó hÉigeartaigh, yang merupakan direktur eksekutif CSER, dan Matthijs Maas, seorang peneliti kecerdasan buatan di University of Copenhagen. Mereka bersenda gurau tentang sebuah ide untuk membuat film aksi mengenai kutu buku berjudul Superintelligence v Blockchain! Mereka juga mendiskusikan sebuah game online bernama Universal Paperclips, yang menceritakan skenario yang tertera di dalam buku Nick Bostrom. Game ini dimainkan dengan cara mengklik mouse Anda secara berulang kali untuk membuat penjepit kertas. Ini cukup memakan waktu lama, tapi keterbatasan seperti ini adalah alasan mesin mungkin merancang cara yang lebih cepat untuk memproduksi perlengkapan kantor.</p>

<p>Akhirnya, pembicaraan beralih ke pertanyaan yang lebih besar, seperti yang sering ditanyakan ketika Tallinn hadir. Tujuan akhir dari penelitian mengenai keamanan kecerdasan buatan adalah menciptakan mesin yang, seperti dikatakan oleh filsuf Cambridge dan salah satu pendiri CSER, Huw Price, “manusia super etis dan kognitif”. Peneliti lain telah bertanya: jika kita tidak ingin kecerdasan buatan menguasai kita, apakah kita sendiri ingin menguasai kecerdasan buatan? Dengan kata lain, apakah kecerdasan buatan berhak memiliki hak? Tallinn berpendapat bahwa pertanyaan ini adalah antropomorfisasi yang tidak perlu. Pendapat ini dengan sendirinya memberi asumsi bahwa kecerdasan sama halnya dengan kesadaran — kesalahpahaman yang disesali banyak peneliti kecerdasan buatan. Sebelumnya pada hari itu, peneliti CSER José Hernández-Orallo bercanda bahwa ketika berdiskusi dengan peneliti kecerdasan buatan, kesadaran disingkat dengan C-Word. (“Dan ‘kehendak bebas’ consciousness disingkat dengan F-Word “kata-F,” tambahnya.)</p>

<p>Di ruangan bawah tanah, Talinn berkata bahwa kesadaran adalah inti dari segala hal. “Ambil contoh sebuah termostat. Tidak ada yang akan mengatakan benda itu mempunyai kesadaran. Tetapi akan akan menjadi tidak nyaman untuk menghadapi alat itu jika Anda berada di ruangan yang bersuhu minus 30 derajat.</p>

<p>Ó hÉigeartaigh menyela. “Akan menjadi lebih baik untuk risau mengenai isu-isu kesadaran,” katanya, “tetapi kita tidak akan mendapatkan kemewahan untuk kuatir tentangnya jika kita tidak menyelesaikan tantangan keselamatan teknisnya terlebih dahulu.</p>

<p>Orang-orang terlalu sibuk dengan kecerdasan buatan yang sangat cerdas, kata Talinn. Bagaimana nantinya bentuk kecerdasan buatan itu? Haruskah kita kuatir ada satu AI yang akan mengambil alih, atau bahkan sekumpulan mereka yang akan mengambil alih? “Menurut hemat kami, yang penting adalah apa yang dilakukan oleh kecerdasan buatan,” tegasnya. Dan hal tersebut, dia meyakini, mungkin masih akan tergantung pada manusia-sampai detik ini.</p>

<p>Diterjemahkan dari Can we stop AI outsmarting humanity? Hantu mesin kecerdasan super yang membahayakan kita bukan hanya cerita dalam fiksi ilmiah, kata para pakar teknologi — jadi bagaimana kita dapat menjamin kecerdasan buatan agar tetap ramah bagi penciptanya? Mara Hvistendahl menulis ide mengenai kecerdasan buatan ini di dalam rubrik Long Read dari The Guardian</p>

    </article>


    





    
    
    




    
    
    

<section id="articleNext" class="section nartrow">
    <h3 class="footer-next-heading">More articles from Faris | Personal Blog</h3>
    <div class="footer-spacer"></div>
    <div class="next-articles-grid" numberOfArticles={numberOfArticles}>
        <div class="post-row">
            
                <a href="https://dzelrahman.github.io/eja_arti/post/emoji-support/" class="article-link"
                 id="article-link-bigger">
                    <div>
                        <div class="image-container">
                            <img src="https://dzelrahman.github.io/eja_arti/images/korupsi-1.jpg" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                Korupsi Bukanlah Masalah, Ia Merupakan Solusi (Bag.1)
                            </h2>
                            <p class="article-excerpt">
                                Memberantas korupsi dengan inovasi
                            </p>
                            <div class="article-metadata">
                                March 3, 2019 · 17 min read
                            </div>
                        </div>
                    </div>
                </a>
            
                <a href="https://dzelrahman.github.io/eja_arti/post/woodland0000/" class="article-link"
                >
                    <div>
                        <div class="image-container">
                            <img src="https://dzelrahman.github.io/eja_arti/images/overload.jpg" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                Berlayar di Arus Informasi
                            </h2>
                            <p class="article-excerpt">
                                Banjir informasi itu nyata, lalu apa sikap kita?
                            </p>
                            <div class="article-metadata">
                                June 6, 2020 · 8 min read
                            </div>
                        </div>
                    </div>
                </a>
            
        </div>
    </div>
</section>

</section>


 <script src="https://dzelrahman.github.io/eja_arti/js/progressBar.js"></script>

        
        <div class="footer-gradient"></div>
    <div class="section narrow">
      <div class="footer-hr"></div>
      <div class="footer-container">
        <div class="footer-text">
          © 2020 Faris | Personal Blog
        </div>
        <div class="social-icon-outer">
    <div class="social-icon-container">
        
    </div>
</div>
    </div>
</div>

    </div>

    
    <script src="https://dzelrahman.github.io/eja_arti/js/prism.js"></script>
</body>

</html>